{
  "hash": "35f8c80ef478e41b37989a34fe4db45a",
  "result": {
    "markdown": "---\ntitle: \"Fuzzy regression discontinuity\"\n---\n\n\n\n\n## Program background\n\nIn this example, we'll use the same situation that we used in the [the example for regression discontinuity](/example/rdd.qmd):\n\n- Students take an entrance exam at the beginning of the school year\n- If they score 70 or below, they are enrolled in a free tutoring program\n- Students take an exit exam at the end of the year\n\nIf you want to follow along, download this dataset and put it in a folder named `data`:\n\n- [{{< fa table >}} `tutoring_program_fuzzy.csv`](/files/data/generated_data/tutoring_program_fuzzy.csv)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)  # ggplot(), %>%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(rdrobust)  # For robust nonparametric regression discontinuity\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\nlibrary(modelsummary)  # Create side-by-side regression tables\nlibrary(kableExtra)  # Fancy table formatting\n\ntutoring <- read_csv(\"data/tutoring_program_fuzzy.csv\")\n```\n:::\n\n\n\n## Noncompliance around a cutoff\n\nIn [the example for regression discontinuity](/example/rdd.qmd), it was fairly easy to measure the size of the jump at the cutoff because compliance was perfect. No people who scored above the threshold used the tutoring program, and nobody who qualified for the program didn't use it. It was a *sharp* design, since program usage looked like this:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](../../../../../../../example/rdd_files/figure-html/check-fuzzy-sharp-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nHowever, seeing a cutoff this sharp and this perfect is fairly rare. It is possible that some people scored higher on the entrace exam and somehow used tutoring, or that some people scored below the threshold but didn't participate in the program, either because they're never-takers, or because they fell through bureaucratic cracks.\n\nMore often, you'll see compliance that looks like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(tutoring, aes(x = entrance_exam, y = tutoring_text, color = entrance_exam <= 70)) +\n  # Make points small and semi-transparent since there are lots of them\n  geom_point(size = 1.5, alpha = 0.5,\n             position = position_jitter(width = 0, height = 0.25, seed = 1234)) +\n  # Add vertical line\n  geom_vline(xintercept = 70) +\n  # Add labels\n  labs(x = \"Entrance exam score\", y = \"Participated in tutoring program\") +\n  # Turn off the color legend, since it's redundant\n  guides(color = \"none\")\n```\n\n::: {.cell-output-display}\n![](rdd-fuzzy_files/figure-html/fuzzy-compliance-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nWe can see the count and percentages of compliance with `group_by()` and `summarize()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntutoring %>%\n  group_by(tutoring, entrance_exam <= 70) %>%\n  summarize(count = n()) %>%\n  group_by(tutoring) %>%\n  mutate(prop = count / sum(count))\n## # A tibble: 4 × 4\n## # Groups:   tutoring [2]\n##   tutoring `entrance_exam <= 70` count   prop\n##   <lgl>    <lgl>                 <int>  <dbl>\n## 1 FALSE    FALSE                   644 0.946 \n## 2 FALSE    TRUE                     37 0.0543\n## 3 TRUE     FALSE                   115 0.361 \n## 4 TRUE     TRUE                    204 0.639\n```\n:::\n\n\nHere we have 36 people who should have used tutoring who didn't (either because they're never-takers and are anti-program, or because the system failed them), and we have 116 people (!!!) who somehow snuck into the program. That should probably be a big red flag for the program administrators. That means that 36.5% of people in the tutoring program shouldn't have been there. Big yikes.\n\nThis is definitely not a sharp design. This is a fuzzy regression discontinuity.\n\n## Visualizing a fuzzy gap\n\nWith regular sharp RD, our goal is to measure the size of the gap or discontinuity in outcome right at the cutoff. [In our sharp example](/example/rdd.qmd#step-4-check-for-discontinuity-in-outcome-across-running-variabl) we did this with different parametric regression models, as well as with the `rdrobust()` function for nonparametric measurement.\n\nRegular parametric regression won't really work here because we have strange compliance issues:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(tutoring, aes(x = entrance_exam, y = exit_exam, color = tutoring)) +\n  geom_point(size = 1, alpha = 0.5) +\n  # Add a line based on a linear model for the people scoring less than 70\n  geom_smooth(data = filter(tutoring, entrance_exam <= 70), method = \"lm\") +\n  # Add a line based on a linear model for the people scoring 70 or more\n  geom_smooth(data = filter(tutoring, entrance_exam > 70), method = \"lm\") +\n  geom_vline(xintercept = 70) +\n  labs(x = \"Entrance exam score\", y = \"Exit exam score\", color = \"Used tutoring\")\n```\n\n::: {.cell-output-display}\n![](rdd-fuzzy_files/figure-html/check-outcome-fuzzy-discontinuity-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nThere's still a visible gap at 70, but there are people who did and did not use the program on both sides of the cutoff.\n\nAnother way to look at this is to make a sort of histogram that shows the probability of being in the tutoring program at different entrance exam scores. 100% of people who score between 25 and 50 on the exam used tutoring, so that's good, but then the probability of tutoring drops to ≈80ish% up until the cutpoint at 70. After 70, there's a 10–15% chance of using tutoring if you're above the threshold.\n\nIf this were a sharp design, every single bar to the left of the cutpoint would be 100% and every single bar to the right would be 0%, but that's not the case here. The probability of tutoring changes at the cutpoint, but it's not 100% perfect.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# This fun code uses cut() to split the entrance exam column into distinct\n# categories (0-5, 5-10, 10-15, etc.). You'll see some strange syntax in the\n# categories it creates: (70, 75]. These ranges start with ( and end with ] for\n# a reason: ( means the range *does not* include the number, while ] means that\n# the range *does* include the number. (70, 75] thus means 71-75. You can\n# reverse that with an argument to cut() so taht it would do [70, 75), which\n# means 70-74.\ntutoring_with_bins <- tutoring %>%\n  mutate(exam_binned = cut(entrance_exam, breaks = seq(0, 100, 5))) %>%\n  # Group by each of the new bins and tutoring status\n  group_by(exam_binned, tutoring) %>%\n  # Count how many people are in each test bin + used/didn't use tutoring\n  summarize(n = n()) %>%\n  # Make this summarized data wider so that there's a column for tutoring and no tutoring\n  pivot_wider(names_from = \"tutoring\", values_from = \"n\", values_fill = 0) %>%\n  rename(tutor_yes = `TRUE`, tutor_no = `FALSE`) %>%\n  # Find the probability of tutoring in each bin by taking\n  # the count of yes / count of yes + count of no\n  mutate(prob_tutoring = tutor_yes / (tutor_yes + tutor_no))\n\n# Plot this puppy\nggplot(tutoring_with_bins, aes(x = exam_binned, y = prob_tutoring)) +\n  geom_col() +\n  geom_vline(xintercept = 8.5) +\n  labs(x = \"Entrance exam score\", y = \"Proportion of people participating in program\")\n```\n\n::: {.cell-output-display}\n![](rdd-fuzzy_files/figure-html/fuzzy-binned-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n## Measuring a fuzzy gap\n\nSo how do we actually measure this gap, given all the compliance issues? Recall from Session 12 that *instruments* let us isolate causal effects for just compliers: they let us find [the complier average causal effect, or CACE](/example/cace.qmd).\n\nBut what should we use as an instrument? Do we use something weird like [the Scrabble score of people's names](http://ftp.iza.org/dp7725.pdf)? Something [overused like rainfall](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3715610)?\n\nNo! In this case, the instrument is fairly easy and straightforward: we create a variable that indicates if someone is above or below the threshold. That's all. This variable essentially measures *what should have happened* rather than what actually happened.\n\nSurprisingly, it meets all the qualifications of an instrument too:\n\n- **Relevance** ($Z \\rightarrow X$ and $\\operatorname{Cor}(Z, X) \\neq 0$): The cutoff causes access to the tutoring program.\n- **Exclusion** ($Z \\rightarrow X \\rightarrow Y$ and $Z \\nrightarrow Y$ and $\\operatorname{Cor}(Z, Y | X) = 0$): The cutoff causes exit exam scores *only through* the tutoring program.\n- **Exogeneity** ($U \\nrightarrow Z$ and $\\operatorname{Cor}(Z, U) = 0$): Unobserved confounders between the tutoring program and exit exam scores are unrelated to the cutoff.\n\n### Fuzzy parametric estimation\n\nLet's make an instrument! We'll also center the running variable just like we did with sharp regression discontinuity:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntutoring_centered <- tutoring %>%\n  mutate(entrance_centered = entrance_exam - 70,\n         below_cutoff = entrance_exam <= 70)\ntutoring_centered\n## # A tibble: 1,000 × 7\n##       id entrance_exam tutoring tutoring_text exit_exam entrance_centered below_cutoff\n##    <dbl>         <dbl> <lgl>    <chr>             <dbl>             <dbl> <lgl>       \n##  1     1          92.4 FALSE    No tutor           78.1            22.4   FALSE       \n##  2     2          72.8 FALSE    No tutor           58.2             2.80  FALSE       \n##  3     3          53.7 TRUE     Tutor              62             -16.3   TRUE        \n##  4     4          98.3 FALSE    No tutor           67.5            28.3   FALSE       \n##  5     5          69.7 TRUE     Tutor              54.1            -0.300 TRUE        \n##  6     6          68.1 TRUE     Tutor              60.1            -1.90  TRUE        \n##  7     7          86   FALSE    No tutor           73              16     FALSE       \n##  8     8          85.7 TRUE     Tutor              76.7            15.7   FALSE       \n##  9     9          85.9 FALSE    No tutor           57.8            15.9   FALSE       \n## 10    10          89.5 FALSE    No tutor           79.9            19.5   FALSE       \n## # … with 990 more rows\n```\n:::\n\n\nNow we have a new column named `below_cutoff` that we'll use as an instrument. Most of the time this will be the same as the `tutoring` column, since most people are compliers. But some people didn't comply, like person 8 here who was *not* below the cutoff but still used the tutoring program.\n\nBefore using the instrument, let's first run a model that assumes the cutoff is sharp. As we did with [the sharp parametric analysis](/example/rdd.qmd#parametric-estimation), we'll include two explanatory variables:\n\n$$\n\\text{Exit exam} = \\beta_0 + \\beta_1 \\text{Entrance exam score}_\\text{centered} + \\beta_2 \\text{Tutoring program} + \\epsilon\n$$\n\nWe'll use a bandwidth of 10:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Bandwidth ±10\nmodel_sans_instrument <- lm(exit_exam ~ entrance_centered + tutoring,\n                            data = filter(tutoring_centered,\n                                          entrance_centered >= -10 &\n                                            entrance_centered <= 10))\ntidy(model_sans_instrument)\n## # A tibble: 3 × 5\n##   term              estimate std.error statistic   p.value\n##   <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept)         59.3      0.504     117.   1.01e-312\n## 2 entrance_centered    0.508    0.0665      7.64 1.65e- 13\n## 3 tutoringTRUE        11.5      0.744      15.5  1.38e- 42\n```\n:::\n\n\nHere, the coefficient for `tutoringTRUE` shows the size of the jump, which is 11.5. This means that participating in the tutoring program *causes* an increase of 11.5 points on the final exam for people in the bandwidth.\n\n**BUT THIS IS WRONG.** This is *not* a sharp discontinuity, so we can't actually do this. Instead, we need to run a 2SLS model that includes our instrument in the first stage, which will then remove the endogeneity built into participation in the program. We'll estimate this set of models:\n\n$$\n\\begin{aligned}\n\\widehat{\\text{Tutoring program}} &= \\gamma_0 + \\gamma_1 \\text{Entrance exam score}_\\text{centered} + \\gamma_2 \\text{Below cutoff} + \\omega \\\\\n\\text{Exit exam} &= \\beta_0 + \\beta_1 \\text{Entrance exam score}_\\text{centered} + \\beta_2 \\widehat{\\text{Tutoring program}} + \\epsilon\n\\end{aligned}\n$$\n\nWe could manually run the first stage model, generate predicted `tutoring` and then use those predicted values in the second stage model [like we did in the instrumental variables example](/example/iv.qmd), but that's tedious and nobody wants to do all that work. We'll use `iv_robust()` from the **estimatr** package instead.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_fuzzy <- iv_robust(\n  exit_exam ~ entrance_centered + tutoring | entrance_centered + below_cutoff,\n  data = filter(tutoring_centered, entrance_centered >= -10 & entrance_centered <= 10)\n)\ntidy(model_fuzzy)\n##                term estimate std.error statistic  p.value conf.low conf.high  df   outcome\n## 1       (Intercept)     60.5       1.0      59.0 1.1e-199     58.5      62.5 401 exit_exam\n## 2 entrance_centered      0.4       0.1       4.0  8.2e-05      0.2       0.6 401 exit_exam\n## 3      tutoringTRUE      9.0       1.9       4.7  4.1e-06      5.2      12.8 401 exit_exam\n```\n:::\n\n\nBased on this model, using `below_cutoff` as an instrument, we can see that the coefficient for `tutoringTRUE` is different now! It's 9.74, which means that the tutoring program *causes* an average increase of 9.74 points on the final exam **for compliers in the bandwidth**.\n\nNotice that last caveat. Because we're working with regression discontinuity, we're estimating a local average treatment effect (LATE) for people in the bandwidth. Because we're working with instrumental variables, we're estimating the LATE for compliers only. That means our fuzzy regression discontinuity result here is *doubly robust*.\n\nIf we compare this fuzzy result to the sharp result, we can see a sizable difference:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# gof_omit here will omit goodness-of-fit rows that match any of the text. This\n# means 'contains \"IC\" OR contains \"Low\" OR contains \"Adj\" OR contains \"p.value\"\n# OR contains \"statistic\" OR contains \"se_type\"'. Basically we're getting rid of\n# all the extra diagnostic information at the bottom\nmodelsummary(list(\"No instrument (wrong)\" = model_sans_instrument,\n                  \"Fuzzy RD (bw = 10)\" = model_fuzzy),\n             gof_omit = \"IC|Log|Adj|p\\\\.value|statistic|se_type\",\n             stars = TRUE) %>%\n  # Add a background color to row 5\n  row_spec(5, background = \"#F5ABEA\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> No instrument (wrong) </th>\n   <th style=\"text-align:center;\"> Fuzzy RD (bw = 10) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 59.254*** </td>\n   <td style=\"text-align:center;\"> 60.506*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.504) </td>\n   <td style=\"text-align:center;\"> (1.026) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> entrance_centered </td>\n   <td style=\"text-align:center;\"> 0.508*** </td>\n   <td style=\"text-align:center;\"> 0.400*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.066) </td>\n   <td style=\"text-align:center;\"> (0.100) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: #F5ABEA !important;\"> tutoringTRUE </td>\n   <td style=\"text-align:center;background-color: #F5ABEA !important;\"> 11.501*** </td>\n   <td style=\"text-align:center;background-color: #F5ABEA !important;\"> 8.997*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.744) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (1.927) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 404 </td>\n   <td style=\"text-align:center;\"> 404 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.373 </td>\n   <td style=\"text-align:center;\"> 0.356 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> F </td>\n   <td style=\"text-align:center;\"> 119.387 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 6.44 </td>\n   <td style=\"text-align:center;\"> 6.53 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\nWe can (and should!) [do all the other things that we talked about in the regression discontinuity example](/example/rdd.qmd#parametric-estimation), like modifying the bandwidth, adding polynomial terms, and so forth to see how robust the finding is. But we won't do any of that here.\n\n### Fuzzy nonparametric estimation\n\nWe can also use nonparametric methods to measure the size of the fuzzy gap at the cutoff. We'll use `rdrobust()` just like we [did in the sharp example](/example/rdd.qmd#nonparametric-estimation-1). The only difference is that we have to add one extra argument. That's it!\n\nTo do fuzzy estimation with `rdrobust()`, use the `fuzzy` argument to specify the treatment column (or `tutoring` in our case). **Importantly** (and confusingly! this took me waaaaay too long to figure out!), you ***do not*** need to specify an instrument (or even create one!). All you need to specify is the column that indicates treatment status—`rdrobust()` will do all the above/below-the-cutoff instrument stuff behind the scenes for you.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam,\n         c = 70, fuzzy = tutoring$tutoring) %>%\n  summary()\n## [1] \"Mass points detected in the running variable.\"\n## Fuzzy RD estimates using local polynomial regression.\n## \n## Number of Obs.                 1000\n## BW type                       mserd\n## Kernel                   Triangular\n## VCE method                       NN\n## \n## Number of Obs.                  237          763\n## Eff. Number of Obs.             162          331\n## Order est. (p)                    1            1\n## Order bias  (q)                   2            2\n## BW est. (h)                  12.336       12.336\n## BW bias (b)                  18.466       18.466\n## rho (h/b)                     0.668        0.668\n## Unique Obs.                     155          262\n## \n## First-stage estimates.\n## \n## =============================================================================\n##         Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n## =============================================================================\n##   Conventional    -0.670     0.077    -8.686     0.000    [-0.821 , -0.518]    \n##         Robust         -         -    -7.376     0.000    [-0.862 , -0.500]    \n## =============================================================================\n## \n## Treatment effect estimates.\n## \n## =============================================================================\n##         Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n## =============================================================================\n##   Conventional     9.351     2.140     4.369     0.000     [5.156 , 13.545]    \n##         Robust         -         -     3.642     0.000     [4.289 , 14.282]    \n## =============================================================================\n```\n:::\n\n\nThat's all! Using nonparametric methods, with a triangular kernel and a bandwidth of ±12.96, the causal effect of the tutoring program for compliers in the bandwidth is 9.683.\n\nWe can (and should!) [do all the other nonparametric robustness checks that we talked about in the regression discontinuity example](/example/rdd.qmd#nonparametric-estimation), like modifying the bandwidth (ideal, half, double) and messing with the kernel (uniform, triangular, Epanechnikov) to see how robust the finding is. But again, we won't do any of that here.\n",
    "supporting": [
      "rdd-fuzzy_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}