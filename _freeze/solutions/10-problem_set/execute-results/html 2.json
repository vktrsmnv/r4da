{
  "hash": "a57464e917d973ddadce5c818cd1e83a",
  "result": {
    "markdown": "---\ntitle: \"Problem Set 10: Suggested Solutions\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n## Dataset\n\nWe will work with the data from the following article and try to replicate the analysis that the author conducted there:\n\n> Broockman, David E. 2013. \"Black Politicians Are More Intrinsically Motivated to Advance Blacks' Interests: A Field Experiment Manipulating Political Incentives.\" *American Journal of Political Science* 57 (3): 521--36.\n\nHere is the abstract from the study:\n\n> Why are politicians more likely to advance the interests of those of their race? I present a field experiment demonstrating that black politicians are more intrinsically motivated to advance blacks' interests than are their counterparts. Guided by elite interviews, I emailed 6,928 U.S. state legislators from a putatively black alias asking for help signing up for state unemployment benefits. Crucially, I varied the legislators' political incentive to respond by randomizing whether the sender purported to live within or far from each legislator's district. While nonblack legislators were markedly less likely to respond when their political incentives to do so were diminished, black legislators typically continued to respond even when doing so promised little political reward. Black legislators thus appear substantially more intrinsically motivated to advance blacks' interests. As political decision making is often difficult for voters to observe, intrinsically motivated descriptive representatives play a crucial role in advancing minorities' political interests.\n\n\n| Variable            | Description                                                 |\n|:---------------|------------------------------------------|\n| `leg_black`         | Legislator receiving email is Black                         |\n| `treat_out`         | Email is from out-of-district                               |\n| `responded`         | Legislator responded to email                               |\n| `totalpop`          | District population                                         |\n| `medianhhincom`     | District median household income                            |\n| `black_medianhh`    | District median household income among Black people         |\n| `white_medianhh`    | District median household income among White people         |\n| `blackpercent`      | Percentage of district that is Black                        |\n| `statessquireindex` | State's Squire index                                        |\n| `nonblacknonwhite`  | Legislator receiving email is neither Black nor White       |\n| `urbanpercent`      | Percentage of district that is urban                        |\n| `leg_senator`       | Legislator receiving email is a senator                     |\n| `leg_democrat`      | Legislator receiving email is in the Democratic party       |\n| `south`             | Legislator receiving email is in the Southern United States |\n\n\n## Task 1: DAG \n\n> Normally in (field) experiments, the variable(s)  manipulated/randomized by researchers is(are) called the *treatment* variable(s). Here, we will be referring to treatment variables in the context of matching, i.e. the predictor that is not randomly distributed but for which we would like to mimic the randomization. In other words, the variables which we are matching on. \n\nBelow you can find a DAG that depicts the relationship between the \"treatment\" variable, `leg_black`, and the `responded`, the outcome variable as well as number of confounders to this relationship. \nThe field experiment, however, included sending emails to legislators, randomizing between the messages from in- and out-of-district. Add this variable to the DAG. You can adapt the DAG below or add the one made with `daggify.net`. \n\n\n```{dot}\n//| echo: false\n//| fig-width: 6\n//| fig-height: 4\n//| out-width: 100%\ndigraph D {\n  node [shape=oval];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"Black Legislator\"];\n  b [label = \"Response to Email\"];\n  c [label = \"District Median Income\"];\n  d [label = \"District % Black\"];\n  e [label = \"Democrat\"];\n  f [label = \"Out-of-district Email\"]\n  \n  {rank=same a b};\n  {rank=same d c e};\n  {rank=sink f};\n  a->b;\n  c->a;\n  c->b;\n  d->a;\n  d->b;\n  e->a;\n  e->b;\n  f->b;\n}\n```\n\n\n> The fact that email was in/out-of-district was randomly assigned by the researcher, so it does not open any backdoors. \n\n\n## Task 2: Explore the Dataset (3 points)\n\n1. Generate a plot representing the data on legislator response rates (`responded`) for black vs. non-black legislators over the type of emails they received. Comment on the plot in 2-3 sentences. \n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(black_politicians %>%\n         arrange(responded),\n       aes(\n         x = if_else(leg_black == 1, \"Yes\", \"No\"),\n         y = if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\"),\n         fill = if_else(responded == 1, \"Yes\", \"No\")\n       )) +\n  geom_jitter(alpha = 0.7, pch = 21, color = \"white\", size = 1.5) +\n  scale_fill_viridis_d(end = 0.8) +\n  labs(fill = \"Legislator Responded\",\n       x = \"Legislator is Black\",\n       y = \"\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](figures/main-dv-plot-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(black_politicians$leg_black, black_politicians$treat_out, black_politicians$responded) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, ,  = 0\n\n   \n       0    1\n  0 1153 1854\n  1   99  122\n\n, ,  = 1\n\n   \n       0    1\n  0 1476  746\n  1   86   57\n```\n:::\n\n```{.r .cell-code}\nplotting <- black_politicians %>%\n  count(leg_black, treat_out, responded) %>%\n  group_by(responded) %>%          # now required with changes to dplyr::count()\n  mutate(prop = prop.table(n))\n\nggplot(plotting,\n       aes(\n         # x = if_else(leg_black == 1, \"Yes\", \"No\"),\n         x = if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\"),\n         y = n,\n         # fill = if_else(leg_black == 1, \"Yes\", \"No\"),\n         fill = if_else(responded == 1, \"Yes\", \"No\") %>% as_factor() %>% fct_rev()\n       )) +\n geom_col(alpha = 0.7, position = position_dodge(),          color = \"white\",) +\n  # scale_fill_manual(values = c(\"gold\", \"deepskyblue4\")) +\n  # facet_grid(.~if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\")) +\n  facet_grid(.~if_else(leg_black == 1, \"Black Legislator\", \"Non-Black Legislator\")) +\n  scale_fill_viridis_d(end = 0.8) +\n  scale_color_viridis_d(end = 0.8) +\n  labs(fill = \"Responded\",\n       x = \"\",\n       y = \"Proportion\",\n       fill = \"\",\n       color = \"\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](10-problem_set_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(plotting,\n       aes(\n         x = if_else(leg_black == 1, \"Black\\nLegislators\", \"Non-Black\\nLegislators\"),\n         # x = if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\"),\n         y = n,\n         # fill = if_else(leg_black == 1, \"Yes\", \"No\"),\n         fill = if_else(responded == 1, \"Yes\", \"No\") %>% as_factor() %>% fct_rev()\n       )) +\n geom_col(alpha = 0.7, position = position_dodge(), color = \"white\",) +\n  # scale_fill_manual(values = c(\"gold\", \"deepskyblue4\")) +\n  facet_grid(.~if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\")) +\n  # facet_grid(.~if_else(leg_black == 1, \"Black Legislator\", \"Non-Black Legislator\")) +\n  scale_fill_viridis_d(end = 0.8) +\n  scale_color_viridis_d(end = 0.8) +\n  labs(fill = \"Response\",\n       x = \"\",\n       y = \"Count\",\n       fill = \"\",\n       color = \"\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](10-problem_set_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(plotting,\n       aes(\n         x = if_else(leg_black == 1, \"Black\\nLegislators\", \"Non-Black\\nLegislators\"),\n         # x = if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\"),\n         y = n,\n         # fill = if_else(leg_black == 1, \"Yes\", \"No\"),\n         fill = if_else(responded == 1, \"Yes\", \"No\") %>% as_factor() %>% fct_rev()\n       )) +\n geom_col(alpha = 0.7, position = position_stack(), color = \"white\",) +\n  # scale_fill_manual(values = c(\"gold\", \"deepskyblue4\")) +\n  facet_grid(.~if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\")) +\n  scale_fill_viridis_d(end = 0.8) +\n  scale_color_viridis_d(end = 0.8) +\n  labs(fill = \"Response\",\n       x = \"\",\n       y = \"Count\",\n       fill = \"\",\n       color = \"\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](10-problem_set_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(plotting,\n       aes(\n         # x = if_else(leg_black == 1, \"Yes\", \"No\"),\n         x = if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\"),\n         y = n,\n         # fill = if_else(leg_black == 1, \"Yes\", \"No\"),\n         fill = if_else(responded == 1, \"Yes\", \"No\") %>% as_factor() %>% fct_rev()\n       )) +\n geom_col(alpha = 0.7, position = position_stack(),          color = \"white\",) +\n  # scale_fill_manual(values = c(\"gold\", \"deepskyblue4\")) +\n  # facet_grid(.~if_else(treat_out == 1, \"Out-of-district\\nEmail\", \"In-district\\nEmail\")) +\n  facet_grid(.~if_else(leg_black == 1, \"Black Legislator\", \"Non-Black Legislator\")) +\n  scale_fill_viridis_d(end = 0.8) +\n  scale_color_viridis_d(end = 0.8) +\n  labs(fill = \"Responded\",\n       x = \"\",\n       y = \"Proportion\",\n       fill = \"\",\n       color = \"\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](10-problem_set_files/figure-html/unnamed-chunk-3-4.png){width=672}\n:::\n:::\n\n\n\n> Answer goes here \n\n2. Run a linear regression model to explore if black legislators are more likely to respond to emails from out-of-district vs. in-district ones in comparison to non-black legislators. Control for the legislator party, senator status, South, and other available sociodemographic characteristics for the districts. You can print out the output with `summary()` for this task. \nComment on the findings: \n- How responsive were legislators when their political incentives were decreased?\n- How did the effect of decreasing legislators’ political incentives vary between legislators of different race?  \n\n\n::: {.cell}\n\n:::\n\n\n> Answer goes here \n\n3. Why could the non-random distribution of race variable be problematic for the analysis? How does matching address this issue? \n\n> Answer goes here \n\n\n## Task 3: Exact Matching (4 points)\n\n\n1. When using matching for preprocessing, we need to disregard the dependent variable, thus we will only be working with treatment and matching variables at this stage. Look at the plot below, which shows the data across all three matching variables and points are colored by the values of the treatment variable. What do you observe regarding the distribution of the treatment variable across the three matching variables? \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-problem_set_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n> Answer goes here \n\n2. Apply the exact matching algorithm to the dataset, and match based on the values of legislator race variable. Store the dataset in `exact_df` object. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# exact_df <- \n```\n:::\n\n\n3. Explore the visualized distribution over matching variables for the matched dataset. The size of the points represents the ratio between the number of treated units to untreated ones within each unique combination of values, subgroup. \nWhat do you observe from this plot: \n- what changes in the distribution of the variables in comparison to the raw data? \n- to what extent do the distributions within treated and untreated groups overlap, in comparison to raw data? \n\n\n::: {.cell}\n\n:::\n\n\n> Answer goes here \n\n4. What can you say about the covariate balance in this matched dataset? Construct the covariate balance plot if you need to answer this question. \n\n> Answer goes here \n\n## Task 4: Nearest Neghbor Matching (6 points)\n\n1. Let's try out a different matching algorithm: nearest neighbor matching with Mahalanobis distance. In a few sentences, explain what is the logic underlying this matching algorithm.\n\n> Answer goes here \n\n2. Now implement the algorithm. Explore if the ordering of observations makes a difference when you match *without* replacement. Compare the original order vs. order by `blackpercent` (`arrange()` function can help). Compare the resulting datasets with `setdiff()`. \n\n\n::: {.cell}\n\n:::\n\n\n\n3. What does covariate balance mean in the context of matching? Which variables would we use to assess covariate balance? E.g., do we need to access balance for main dependent variable, treatment (the variable we used to match on), the matching variables, other variables in the dataset? Why (not)? \n\n> Answer goes here \n\n4. Compare the matched datasets when matching *with* and *without* replacement. Which one produces better covariate balance? Why? Generate a covariate balance plot if you need to answer this question. \n\n\n::: {.cell}\n\n:::\n\n\n> Answer goes here \n\n5. Explore the _distributions_ of matching variables for all three matching variables. What do you observe on the plots? Comment in 3-4 sentences. \n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- bal.plot(nn, # matchit object \n         var.name = \"blackpercent\" # name of the variable you are comparing \n         )\np2 <- bal.plot(nn, # matchit object \n         var.name = \" \" # name of the variable you are comparing \n         )\n  \np3 <- bal.plot(nn, # matchit object \n         var.name = \" \" # name of the variable you are comparing \n         )\n  \np1 / p2 / p3  \n```\n:::\n\n\n> Answer goes here\n\n6. Adapt the code from `exact-matching-plot` chunk to show the distributions for the dataset with the best covariate balance that you have obtained so far with nearest neighbor matching. What are the differences to the same plot from exact matching? How do you explain them?  \n\n> Answer goes here \n\n\n::: {.cell}\n\n:::\n\n\n\n## Task 5: Estimation on Matched Datasets (2 points)\n\nFinally, let's move to the estimation part. You will now need to run the regression with the main dependent variable, i.e. whether the legislator responded to the email or not, and estimate the same model as in task 2. \n\n1. Use the matched dataset that provided you with the best covariate balance so far as well as had a reasonable number of observations. Don't forget to include the *weights* argument to account for the fact that some untreated units may be in the dataset more than once! Explain your findings. Do the results hold after improving balance between the districts with and without black legislators?   \n\n\n::: {.cell}\n\n:::\n\n\n2. (Optional) Use simulations to present the results and calculate first differences for the relevant scenarios. To save you a bit of time, I provide you with a list of average case scenarios for the control variables that could be passed into the `setx()` function. \n\n\n::: {.cell}\n\n:::\n\n\n## Task 6: Inverse Probability Weighting (4 points)\n\nRecall that the last method we talked about was related to propensity scores. \n\n1. What does a propensity score for each observation depict? \n\n> Answer goes here\n\n2. In a simplified version of the DAG (without the in-district vs. out-of-district orogins of email), propensity score can be depicted as follows. Explain in a few sentences how accounting for it impacts the open paths between the *Race* and *Response* variables. \n\n> Answer goes here \n\n\n```{dot}\n//| echo: false\n//| fig-width: 6\n//| fig-height: 4\n//| out-width: 100%\ndigraph D {\n  node [shape=oval];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"Black Legislator\"];\n  b [label = \"Response to Email\"];\n  d [label = \"District Median Income\"];\n  c [label = \"District % Black\"];\n  e [label = \"Democrat\"];\n  f [label = \"Propensity Score\"];\n  \n  {rank=same a b};\n  {rank=same d c e};\n  {rank=sink a};\n  a->b;\n  c->f;\n  c->b;\n  d->f;\n  d->b;\n  e->b;\n  e->f;\n  f->a;\n}\n```\n\n\n\n3. Below you can find the code that calculates the propensity scores as well as the inverse probability weights from them. Note that it’s important to check the values of your inverse probability weights, as sometimes they can get too big (like if the very-very unlikely-to-be-treated unit actually was in the treatment group), which could mess with the estimation. To fix this, we can truncate weights at some lower level. There's no universal rule of thumb for a good maximum weight, and we can often see 10 used as such a cutoff. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nps_model <- glm(\n    leg_black ~ medianhhincom + blackpercent + leg_democrat,\n    data = black_politicians,\n    family = binomial(link = \"logit\")\n  )\n\nipw_df <- augment_columns(# unlike augment(), this adds more columns\n  ps_model,\n  black_politicians,\n  type.predict = \"response\"\n  ) %>% \n  # The predictions are in a column named \".fitted\", so we rename it here\n  rename(propensity = .fitted) %>%\n  mutate(ipw = (leg_black / propensity) + ((1 - leg_black) / (1 - propensity)),\n         ipw = if_else(ipw > 10, 10, ipw) # truncate very high IPWs\n         )\n```\n:::\n\n\n4. Use the calculated weights to re-estimate your main model. Do the results hold again? \n\n\n::: {.cell}\n\n:::\n\n\n5. (Option) Create a nice table for all the models you estimated. \n\n## (Optional) Task 7: Matching by Hand (3 extra points)\n\nThis part of the problem set walks you through the process of exact matching when done by hand. Based on this code, you can do the coarsened exact matching and explore how the cut-offs used for coarsening impact the outcomes. \n\n### Exact Matching\n\nLet's start with exact matching. You can find the code in the chunk below. Here is what we do step-by-step:\n\n- We use `group_by()` to create groups with every unique combination of matching variables. In this case, we are using `blackpercent`, `medianhhincom`, `leg_democrat` as our matching variables. \n- We then create new variables: \n  - `n` is the size of the group, i.e. how many observations have that unique combination in matching variables\n  - `treated_in_group` counts the number of treated units within each group \n  - `untreated_in_group` counts the number of untreated units within each group\n- Next, we move on and remove the groups, subclasses, that have only one observation in them (i.e. cases where there are no matches found at all). We also remove the groups that contain only the treated units and only untreated units as they also did not match the treated units to untreated ones. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmanual_exact_df <- black_politicians %>%\n  group_by(blackpercent, medianhhincom, leg_party) %>%\n  mutate(\n    group_id = cur_group_id(),\n    n = n(),\n    treated_in_group = sum(leg_black),\n    untreated_in_group = sum(leg_black == 0)\n  ) %>%\n  filter(\n    n > 1,\n    untreated_in_group > 0,\n    treated_in_group > 0\n  ) \n\n# check ourselves with the package   \nexact_df <-\n  matchit(\n    leg_black ~ medianhhincom + blackpercent + leg_party,\n    data = black_politicians,\n    method = \"exact\",\n    ) %>%\n  match.data()\n\n# compare the datasets (only the first 14 columns with actual data)\nsetdiff(manual_exact_df[,1:14], exact_df[,1:14])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 0 × 14\n# Groups:   blackpercent, medianhhincom [0]\n# ℹ 14 variables: leg_black <dbl>, treat_out <dbl>, responded <dbl>,\n#   totalpop <dbl>, medianhhincom <dbl>, black_medianhh <dbl>,\n#   white_medianhh <dbl>, blackpercent <dbl>, statessquireindex <dbl>,\n#   nonblacknonwhite <dbl>, urbanpercent <dbl>, leg_senator <dbl>,\n#   leg_democrat <dbl>, south <dbl>\n```\n:::\n:::\n\n\nRecall that we are trying to estimate the average treatment effect on the treated, so to compare the actual outcome of the dependent variable, responding to email, given that the *treatment* was administered (i.e. the legislator was black) to the *counterfactual*, i.e. the hypothetical situation of the legislator in that same district not being black. This means that we want to have the situation of just one matched untreated unit per every treated unit. Let's see if it is the case:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmanual_exact_df %>% \n  reframe(ratio_in_group = treated_in_group / untreated_in_group) %>% \n  distinct() %>%\n  pull(ratio_in_group) %>%\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n0.333333333333333               0.5 0.666666666666667                 1 \n                6                 6                 1                 4 \n                2                 3 \n                3                 1 \n```\n:::\n:::\n\n\nAs we see, the ratio is equal only in 4 subgroups. In 6 groups, we have 3 treated per one treated, while in 1 subgroup, we have 3 treated vs. 1 untreated units (0.33 ratio). In order to balance out our observations within groups to the 1:1 ratio, we need to \"upweight\" the untreated units when $n_{untreated} < n_{treated}$ within a subgroup and \"downweight\" them if $n_{untreated} > n_{treated}$. This way, we would obtain the difference in means for the outcome variable within the subgroup. Thus we need to weigh the untreated units with this ratio: \n\n$$\nw^{untreated}_{subgroup} = \\frac{n_{treated}}{n_{untreated}}, ~\\text{ and }~w^{treated}_{subgroup} = 1\n$$\n\nIn addition to the part of the weights that equals out the relative shares of treated vs. untreated units, we want normalize these weights so that their sum equals the number of observations in the matched dataset. This is important for calculating the standard errors. Hence we additionally add the ratio of $N_{untreated}/N_{treated}$ for the complete matched dataset (not within each subgroup as before). The weights then become:\n\n$$\nw^{untreated} = \\frac{N_{untreated}}{N_{treated}}\\times \\frac{n_{treated}}{n_{untreated}}, ~\\text{ and }~w^{treated} = 1\n$$\n\nThis is the manual implementation in `R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmanual_exact_df <- manual_exact_df %>% \n  mutate(ratio_in_group =  treated_in_group / untreated_in_group) %>%\n  ungroup() %>%\n  mutate(ratio_total = sum(leg_black == 0)/ sum(leg_black == 1),\n         weights = (ratio_total * ratio_in_group),\n         weights = if_else(leg_black == 1, 1, weights)) \n\n# check with package \ncbind(\"Manual\" = manual_exact_df$weights %>% table(),\n      \"MatchIt\" = exact_df$weights %>% table()) %>%\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|                  | Manual| MatchIt|\n|:-----------------|------:|-------:|\n|0.506172839506173 |     18|      18|\n|0.759259259259259 |     12|      12|\n|1                 |     27|      27|\n|1.01234567901235  |      3|       3|\n|1.51851851851852  |      4|       4|\n|3.03703703703704  |      3|       3|\n|4.55555555555556  |      1|       1|\n:::\n:::\n\n\nNow we can proceed to the estimation step (with a simplified model): \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# same with linear regression \nm1 <- lm(responded ~ leg_black, exact_df, weights = weights)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = responded ~ leg_black, data = exact_df, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-0.9750 -0.4074 -0.3250  0.4916  0.9467 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.45679    0.07854   5.816 1.92e-07 ***\nleg_black   -0.04938    0.12464  -0.396    0.693    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5029 on 66 degrees of freedom\nMultiple R-squared:  0.002373,\tAdjusted R-squared:  -0.01274 \nF-statistic: 0.157 on 1 and 66 DF,  p-value: 0.6932\n```\n:::\n:::\n\n\nThe average treatment effect is equal to -0.04, but uncertainty about it does not allow us to say that it is statistically different from zero. \n\nNote that we did not need to control for the matching variables any more, as we artificially removed the variation in them, which could explain the differences in the outcome. The coefficient for our treatment variable does not change if we include matching variables as the controls: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm(responded ~ leg_black + blackpercent + medianhhincom + leg_democrat,\n  exact_df,\n  weights = weights\n)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = responded ~ leg_black + blackpercent + medianhhincom + \n    leg_democrat, data = exact_df, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-1.2102 -0.3742 -0.2896  0.4951  0.8799 \n\nCoefficients: (1 not defined because of singularities)\n                Estimate Std. Error t value Pr(>|t|)\n(Intercept)    0.3697938  0.2326204   1.590    0.117\nleg_black     -0.0493827  0.1258499  -0.392    0.696\nblackpercent   0.2399234  0.2793993   0.859    0.394\nmedianhhincom  0.0007816  0.0383657   0.020    0.984\nleg_democrat          NA         NA      NA       NA\n\nResidual standard error: 0.5078 on 64 degrees of freedom\nMultiple R-squared:  0.01375,\tAdjusted R-squared:  -0.03248 \nF-statistic: 0.2975 on 3 and 64 DF,  p-value: 0.8271\n```\n:::\n:::\n\n\n### CEM \n\nYour job now is to adjust the code above for the CEM application. Recall that we need to split the continuous variables into a number of bins to reduce the dimensionality. You can use `cut()` function to make such bins:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncut(black_politicians$blackpercent, breaks = 5) %>%\n  table() %>% \n  kable()\n```\n\n::: {.cell-output-display}\n|.                 | Freq|\n|:-----------------|----:|\n|(-0.000673,0.195] | 4799|\n|(0.195,0.39]      |  432|\n|(0.39,0.585]      |  178|\n|(0.585,0.78]      |  161|\n|(0.78,0.975]      |   23|\n:::\n:::\n\n\n1. Adjust the code below to create such binned versions of the variables. Split `blackpercent` into 12 bins and `medianhhincom` into 12 (these are arbitrary values). Note that `leg_democrat` is categorical, so you don't need to split it. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmanual_cem_df <- black_politicians %>%\n  mutate(\n    ### add variables \n  ) %>% \n  group_by(blackpercent, medianhhincom, leg_party) %>%\n  mutate(\n    subclass = cur_group_id(),\n    n = n(),\n    treated_in_group = sum(leg_black),\n    untreated_in_group = sum(leg_black == 0)\n  ) %>%\n  filter(\n    n > 1,\n    untreated_in_group > 0,\n    treated_in_group > 0\n  ) %>%\n  mutate(ratio_in_group =  treated_in_group / untreated_in_group) %>%\n  ungroup() %>%\n  mutate(ratio_total = sum(leg_black == 0)/ sum(leg_black == 1),\n         weights = (ratio_total * ratio_in_group),\n         weights = if_else(leg_black == 1, 1, weights)) \n\n# quick & dirty plots to assess the balance \n# note that we need to apply weights, too! \nblackpercent <- ggplot(manual_cem_df,\n       aes(x = blackpercent,\n           color = factor(leg_black),\n           group = factor(leg_black))) +\n  geom_density(aes(weight = weights))\n\nmedianhhincom <- ggplot(manual_cem_df,\n       aes(x = medianhhincom,\n           color = factor(leg_black),\n           group = factor(leg_black))) +\n  geom_density(aes(weight = weights))  \n\nleg_democrat <- ggplot(manual_cem_df,\n       aes(x = leg_democrat,\n           color = factor(leg_black),\n           group = factor(leg_black))) +\n  geom_density(aes(weight = weights))\n\n# plot all conditional distributions \nleg_democrat / blackpercent / medianhhincom\n```\n:::\n\n\n\n2. Try out a few different values for thresholds to see which ones produce best distributions. Show the combination that produced best covariate balance.  \n\n\n::: {.cell}\n\n:::\n\n\n3. Comment on the plot generated from your matched dataset. How does the ratio between treated and untreated units seem to look across the variables? What are the differences to exact matching? \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  manual_cem_df %>%\n    group_by(subclass) %>%\n    mutate(n = if_else(\n      leg_black == 1,\n      1,\n      sum(leg_black == 1) / sum(leg_black == 0)\n    )) %>%\n    arrange(leg_black, n),\n  aes(\n    medianhhincom,\n    blackpercent,\n    fill = factor(leg_black),\n    size = n\n  )\n) +\n  geom_jitter(\n    alpha = 0.7,\n    pch = 21,\n    color = \"grey80\",\n    width = 0.1,\n    height = 0.01\n  ) +\n  scale_fill_viridis_d(end = 0.8) +\n  facet_wrap(vars(leg_party)) +\n  labs(fill = \"Treatment Variable (Legislator is Black)\",\n       size = \"Units in Subgroup\",\n       y = \"Share of Black Voters in District\",\n       x = \"Median Household Income in District\") +\n  theme(legend.position = \"bottom\",\n        legend.box = \"vertical\")\n```\n:::\n",
    "supporting": [
      "10-problem_set_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}