{
  "hash": "eb06270496b01488e3cd721a466c94f8",
  "result": {
    "markdown": "---\ntitle: \"Matching\"\nsubtitle: \"Data Analytics and Visualization with R<br>Session 10\"\ntitle-slide-attributes:\n  data-background-size: stretch\n  data-slide-number: none\nauto-stretch: false\ninstitute: \"University of Mannheim<br>Spring 2023\"\nauthor: \"Viktoriia Semenova\"\nfooter: \"[üîó r4da.live](https://r4da.live/)\"\nlogo: images/logo.png\nformat:\n  revealjs:\n    theme: ../slides.scss\n    transition: fade\n    incremental: true   \n    slide-number: true\n    chalkboard: true\nexecute:\n  echo: true\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 80\n---\n\n\n\n\n# Matching and Weighting Methods\n\n## Ideal Setting: Random Experiment {.smaller}\n\n-   When we run a randomized experiment, we are making sure that, on average,\n    the treated and control groups are exactly the same before we apply\n    treatment\n-   *Gold standard* implies that all causal inferences will be valid it you do\n    the experiment right. Why?\n-   Randomization solves many internal validity issues:\n    -   Selection: Treatment and control groups are comparable; people don't\n        self-select\n-   Goal: estimate ATE (average treatment effect)/CATE (conditional ATE)/ATT\n    (ATE on the Treated)\n-   Under randomization, ATE = ATT because the selection bias is zero\n\n## Matching Is A Way of Closing Backdoors\n\n\n```{dot}\n//| echo: false\n//| fig-width: 6\n//| fig-height: 4\n//| out-width: 100%\ndigraph D {\n  node [shape=circle];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"X\"];\n  b [label = \"Y\"];\n  c [label = \"Z\"];\n  d [label = \"W\"];\n  \n  {rank=same a b};\n  {rank=same d c};\n  {rank=sink a};\n  a->b;\n  c->a;\n  c->b;\n  d->a;\n  d->b;\n}\n```\n\n\n. . .\n\n> Selecting a sample where people have similar levels of W (Z) is one way of\n> controlling for W (Z)\n\n## Why Matching? {.smaller}\n\n-   Reduces dependence of estimates on parametric models (i.e. coefficient\n    estimates do not depend heavily on the model specification)\n\n    -   Model dependence ‚Üí researcher discretion ‚Üí bias\n\n-   Makes counterfactual comparisons more transparent: we make comparisons\n    across comparable units\n\n-   Alternative way to statistical control to close the backdoors\n\n-   But: matching is **NOT** a solution for selection on unobservables, i.e. we\n    still need to list all plausible confounders and assume that they are enough\n\n::: task\nMatching is an *estimation* technique, not an identification strategy\n:::\n\n## Model Dependence: All Data {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n$$\n\\color{white}{\\beta_0 \\text{E}^2}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/matching-general-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Model Dependence: All Data {.smaller}\n\n$$\n\\color{white}{\\beta_0 \\text{E}^2} \\text{Outcome} = \\beta_0 + \\beta_1 \\text{Education} + \\beta_2 \\text{Treatment} \\color{white}{\\beta_0 \\text{E}^2}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/matching-dependency1-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Model Dependence: All Data {.smaller}\n\n$$\n\\text{Outcome} = \\beta_0 + \\beta_1 \\text{Education} + \\beta_2 \\text{Education}^2 + \\beta_3 \\text{Treatment}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/dependency2-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Model Dependence: Subset {.smaller}\n\n$$\n\\color{white}{\\text{Outcome} = \\beta_0 + \\beta_1 \\text{Education} + \\beta_2 \\text{Education}^2 + \\beta_3 \\text{Treatment}}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/reduced-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Model Dependence: Subset {.smaller}\n\n$$\n\\color{white}{\\beta_0 \\text{E}^2} \\text{Outcome} = \\beta_0 + \\beta_1 \\text{Education} + \\beta_2 \\text{Treatment} \\color{white}{\\beta_0 \\text{E}^2}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/reduced-dependency1-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Model Dependence: Subset {.smaller}\n\n$$\n\\text{Outcome} = \\beta_0 + \\beta_1 \\text{Education} + \\beta_2 \\text{Education}^2 + \\beta_3 \\text{Treatment}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/reduced-dependency2-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n<!-- --- -->\n\n<!-- **How do we know that we can remove these points?** -->\n\n<!-- ```{r reduced-again, echo=FALSE, fig.width=12, fig.height=5.75, out.width=\"100%\"} -->\n\n<!-- ggplot(all_data, aes(x = education, y = outcome, fill = treatment)) + -->\n\n<!--   geom_point(aes(alpha = type), size = 5, pch = 21, color = \"white\") + -->\n\n<!--   scale_fill_manual(values = c(\"#440154FF\", \"#7AD151FF\"), name = NULL) + -->\n\n<!--   scale_alpha_manual(values = c(1, 0.4), name = NULL) + -->\n\n<!--   guides(alpha = FALSE, color = FALSE) + -->\n\n<!--   labs(x = \"Education\", y = \"Outcome\") + -->\n\n<!--   coord_cartesian(xlim = c(8, 30), ylim = c(0, 15)) + -->\n\n<!--   # theme_bw(base_size = 20, base_family = \"Fira Sans Condensed\") + -->\n\n<!--   theme(legend.position = \"bottom\", -->\n\n<!--         legend.margin = margin(t = 0, b = 0)) -->\n\n<!-- ``` -->\n\n## Matching in Nutshell {.smaller}\n\n-   We want to mimic the *gold standard*, RCT, by artificially creating a\n    *\"control\"* group from the untreated observations to compare to our\n    *treated* group\n-   In regression, we did this by removing explained variation with statistical\n    controlling and comparing *within* values of control variables\n    (explain-and-subtract the differences)\n-   In matching, we are doing this more explicitly by constructing a *\"control\"*\n    group so that we compare treated cases to untreated ones that are closest on\n    the values of all confounders\n-   We can't observe what would have happened in the *counterfactual* where\n    treated units didn't get treatment, but if we pick the most-comparable\n    untreated group possible, that's about as close as we can get\n-   Assuming that the variables we picked are enough to block all the back\n    doors, then such an artificially selected control group closes all the back\n    doors\n-   Matching works because picking a sample where people have similar levels of\n    $W$ is one way of controlling for $W$: once we remove all the variation\n    related to $W$, the leftover variation is explained by the treatment\n\n## Workflow for Matching {.smaller}\n\n**Step 1: Preprocessing. Do something to guess or model the assignment to\ntreatment**\n\n0.  Hide the your main outcome variable for a while\n1.  Pick a set of variables (confounders) to match on, i.e. *matching variables*\n2.  Separate out the treated and untreated cases\n3.  For each treated observation, check how \"close\" each untreated observation\n    is on the matching variables and select the closest one (or few)\n\n**Step 2: Estimation. Use the new trimmed/preprocessed data to build a model and\ncalculate the effects**\n\n4.  Go back to the main model and compare the average treated outcome vs. the\n    average untreated outcome\n\n**Matching methods differ in how they deal with steps 3 and 4.**\n\n# Various Matching Methods\n\n## Example for Two Counfounders\n\n\n```{dot}\n//| echo: false\n//| fig-width: 6\n//| fig-height: 4\n//| out-width: 100%\ndigraph D {\n  node [shape=oval];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"Treatment\"];\n  b [label = \"Outcome\"];\n  c [label = \"Education\"];\n  d [label = \"Age\"];\n  \n  {rank=same a b};\n  {rank=same d c};\n  {rank=sink a};\n  a->b;\n  c->a;\n  c->b;\n  d->a;\n  d->b;\n}\n```\n\n\n\n\n## Exact Matching {.smaller}\n\n1.  **Preprocessing step**\n\n-   Choose matches for treated units that have the *same* value in each $X$\n-   Discard all unmatched control units\n\n2.  **Estimation step**\n\n-   Calculate the effect of interest\n\n::: task\n-   Straightforward process\n-   No matching bias introduced\n-   Not feasible with high-dimesional or continuous data\n-   Strongly reduces the number of units if works\n:::\n\n## Exact Matching: No Observations Matched {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n## Coarsened Exact Matching {.smaller}\n\n1.  **Preprocessing step**\n\n-   Discretize and group covariates into substantively meaningful bins\n-   Exact match on these bins ‚áù accounts for interactions\n-   Have to drop treated units in bins with no controls (lack of overlap) ‚áù\n    changes estimand\n-   Allows you to control bias/variance trade-off through coarsening\n\n2.  **Estimation step**\n\n-   Calculate the effect of interest (ATE, ATT, ATC)\n-   Weight the untreated observations so each treated observation is matched to\n    the same number of untreated ones\n\n::: task\n-   Allows to control the amount of imbalance up front by setting the degree of\n    the coarsening: coarser means more imbalance, fineness means less imbalance\n    but also fewer matched units\n-   Can still break down in high dimensional datasets\n:::\n\n## Coarsened Exact Matching Results {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n\n\n## Nearest Neighbor Matching {.smaller}\n\n1.  **Preprocessing step**\n\n-   Find untreated observations that are very close/similar to treated\n    observations based on confounders\n-   We can define closeness using *lower-dimensional* distance metrics, i.e. we\n    reduce dimensionality in confounders\n-   Many different way to calculate the distance, e.g. propensity score,\n    Euclidean, or Mahalanobis distance (accounts for covariances between\n    variables)\n\n2.  **Estimation step**\n\n-   Calculate the effect of interest on matched dataset\n\n::: task\n-   Order of the matching matters in terms of which units get matched to which\n    other units (when matching without replacement)\n:::\n\n## Distance Measures {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n#### Euclidean distance\n\nFor observations $X_1$ and $X_2$ with $K$ number of matching variables:\n\n$$\nd(X_1,X_2) = \\sqrt{\\frac{\\sum_{k=1}^K(X_{1k} - X_{2k})^2}{\\hat\\sigma^2_k}},\n$$ where $\\hat\\sigma^2_k$ is the standard deviation of the $k$th variable\n\n-   Standardize the matching variables for them to have equal weight on the\n    measure (divide by variables' st. deviation)\n-   For each matching variable, compute the difference between values for two\n    observations of interest and square that difference\n-   Sum the squared differences to get a single number and take a square root of\n    that number\n:::\n\n::: {.column width=\"50%\"}\n#### Mahalanobis distance\n\n$$\nd(X_1,X_2) = \\sqrt{{(X_1-X_2)}'\\widehat\\Sigma^{-1}(X_1-X_2)}\n$$\n\n-   Euclidean distance adjusted for covariance in the data, $\\hat\\Sigma$ (i.e.\n    not only the variance of each variables separately as before)\n-   Intuition: if $X_k$ and $X_{k'}$ are two covariates that are highly\n    correlated, then their contribution to the distances should be lower\n    -   Easy to get close on correlated covariates ‚áù downweight\n    -   Harder to get close on uncorrelated covariates ‚áù upweight\n-   **This is what we want to use!**\n:::\n:::\n\n## Distance Measures {.smaller}\n\n![](images/dist.jpeg)\n\n## 1:1 Nearest Neighbour Matching without Replacement {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/edu-age-unmatched-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## 1:1 Nearest Neighbour: Pairs {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/edu-age-matched-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## 1:1 Nearest Neighbour: Matched Data {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/edu-age-trimmed-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Problem: Curse of Dimensionality {.smaller}\n\n![](https://www.i2tutorials.com/wp-content/media/2019/09/Curse-of-Dimensionality-i2tutorials.png)\n\n-   As the number of matching variables grows, the likelihood of finding exact\n    matches, or approximate ones, for all units falls quickly\n-   The more covariates we have, the higher will be the distance between units\n    and their matches\n\n## Other Matching Choices {.smaller}\n\n-   **Matching ratio:** how many control units per treated?\n    -   Lower reduces bias (only use the closest matches)\n    -   Lower increases variance\n    -   ATT is easy to calculate with 1:1 exact matches on the treated units\n    -   If number of control units varies by treated unit, need to weight\n        observations to ensure balance\n-   **With or without replacement:** same control matched to multiple treated?\n    -   With replacement gives better matches & matching order doesn't matter\n    -   Without replacement simplifies variance estimation\n-   **Caliper:** drop poor matches?\n    -   Only keep matches below an arbitrary distance threshold\n    -   Reduces imbalance, but if you drop treated units, estimand changes from\n        ATT (ATE)\n\n# Inverse Probability Weighting\n\n## Weighting {.smaller}\n\n> Weighting for surveys: down-weight over-sampled respondents\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|           | Young | Middle | Old |\n|:----------|:-----:|:------:|:---:|\n|Population |  30%  |  40%   | 30% |\n|Sample     |  60%  |  30%   | 10% |\n:::\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|           |       Young        |        Middle        |       Old        |\n|:----------|:------------------:|:--------------------:|:----------------:|\n|Population |        30%         |         40%          |       30%        |\n|Sample     |        60%         |         30%          |       10%        |\n|Weight     | 30 / 60<br>**0.5** | 40 / 30<br>**1.333** | 30 / 10<br>**3** |\n:::\n:::\n\n\n-   Multiply weights by average values (or use in regression) to adjust for\n    importance\n\n## Propensity Scores {.smaller}\n\n1.  **Preprocessing step:**\n\n-   Predict the probability of assignment to treatment using a model (e.g. with\n    logit). This is the *propensity score*.\n\n$$\n\\operatorname{log} \\frac{p_\\text{Treated}}{1 - p_\\text{Treated}} = \\beta_0 + \\beta_1 \\text{Education} + \\beta_2 \\text{Age}\n$$\n\n2.  **Estimation step:** Calculate the effect of interest\n\n-   Use propensity scores (predicted probabilities) to weight observations by\n    how \"weird\" they are:\n    -   Observations with high probability of treatment who don't get it (and\n        vice versa) have higher weight\n\n$$\nIPW = \\frac{\\text{Treatment}}{\\text{Propensity}} + \\frac{1 - \\text{Treatment}}{1 - \\text{Propensity}}\n$$\n\n::: task\n-   Propensity scores should **not** be used for NN matching as a measure of\n    distance (King and Nielsen 2019)\n-   Instead, we can use them to weight each observation in the control group\n    such that it looks like the treatment group\n-   You may want to trim the weights when they get too high (e.g., above 10)\n:::\n\n## Inverse Probability Weights {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglm(treatment ~ age + education, edu_age, family = \"binomial\") %>%\n  augment(type.predict = \"response\") %>%\n  mutate(treatment = treatment %>% as.numeric() - 1) %>%\n  dplyr::select(education, treatment, age, propensity = .fitted) %>%\n  mutate(ip_weight = (treatment / propensity) + ((1 - treatment) / (1 - propensity))) %>% \n  slice_sample(n = 6) %>%\n  kable()\n```\n\n::: {.cell-output-display}\n| education| treatment|      age| propensity| ip_weight|\n|---------:|---------:|--------:|----------:|---------:|\n|  21.31138|         0| 56.02607|  0.2014031|  1.252196|\n|  17.26641|         1| 39.98411|  0.4491284|  2.226535|\n|  18.56842|         1| 61.59597|  0.2063161|  4.846931|\n|  22.43608|         0| 65.42724|  0.1263407|  1.144611|\n|  21.49260|         0| 50.59117|  0.2416299|  1.318617|\n|  18.36010|         1| 39.27205|  0.4288673|  2.331723|\n:::\n:::\n\n\n-   Inverse-probability weighting removes confounding by creating a\n    \"pseudo-population\" in which the treatment is independent of the measured\n    confounders\n-   Units who were assigned to the treatment group even though they were much\n    more likely to be assigned to the control group are a rare, and we want to\n    upweight them\n\n--------------------------------------------------------------------------------\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/edu-age-ipw-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n<!-- Different ways to measure distance -->\n\n<!-- Mahalanobis distance / Euclidean distance -->\n\n# Covariate Balance Assessment\n\n## Covariate Balance\n\n-   Goal of matching is to maximize covariate balance across *treatment* and\n    *\"control\"* groups\n    -   Ideally, we need to see if the joint distribution of all covariates in\n        matching variables is similar between treated and matched controls\n    -   In practice, check lower-dimensional summaries (e.g., standardized mean\n        difference, variance ratio, empirical CDF difference)\n-   Hypothesis tests for balance are problematic: Dropping units can lower power\n    (‚Üë p-values) without a change in balance\n-   If *\"control\"* and *treatment* groups differ, on average, try again\n\n## Covariate Balance Plot for NN Matching\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-matching_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n## Problems When Using Summary Stats\n\n![](https://theeffectbook.net/the-effect_files/figure-html/matching-bad-balance-distribution-1.png)\n\n## More Details on Workflow\n\n1.  Check the balance before the matching\n2.  Decide on covariates for which balance must be achieved\n3.  Choose matching type (compute/estimate the distance/balancing score if\n    necessary)\n4.  Condition on the distance measure (e.g., using matching, weighting, or\n    subclassification), i.e. create matched dataset\n5.  Assess balance on the covariates of interest; if poor, repeat steps 2-5\n6.  Estimate the treatment effect in the conditioned sample (i.e. matched\n    dataset)\n\n## Assumptions {.smaller}\n\n#### Conditional Independence Assumption\n\n-   The set of matching variables you've chosen is enough to close all back\n    doors\n\n#### Common Support Assumption\n\n-   There are appropriate control observations to match with treated units\n-   There must be substantial overlap in the distributions of the matching\n    variables comparing the treated and control observations\n\n#### Balance\n\n-   The approach to selecting a matched group has closed back doors for the\n    variables we're interested in\n\n## Main Takeaways\n\n-   Matching is a technique to reduce model dependence and avoid parametric\n    modeling assumptions when no unmeasured confounders holds\n-   Lots of different ways to match, each has advantages and disadvantages. Try\n    different methods and aim for best covariate balance\n-   Pay careful attention to the quantity of interest when you drop units\n",
    "supporting": [
      "10-matching_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}