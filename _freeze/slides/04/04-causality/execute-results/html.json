{
  "hash": "4fdecd0c05af305729ff1fba72eb524d",
  "result": {
    "markdown": "---\ntitle: \"Causality\"\nsubtitle: \"Data Analytics and Visualization with R<br>Session 4\"\ntitle-slide-attributes:\n  data-background-size: stretch\n  data-slide-number: none\nauto-stretch: false\ninstitute: \"University of Mannheim<br>Spring 2023\"\nauthor: \"Viktoriia Semenova\"\nfooter: \"[ðŸ”— r4da.live](https://r4da.live/)\"\nlogo: images/logo.png\nformat:\n  revealjs:\n    theme: ../slides.scss\n    transition: fade\n    incremental: true   \n    slide-number: true\n    chalkboard: true\nexecute:\n  echo: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Warm Up\n\n## Your GitHub Stats ðŸ¤“\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/PS03_by_hour.png)\n:::\n\n::: {.column width=\"50%\"}\n![](images/PS01_by_wday.png)\n:::\n:::\n\n## Quiz: Which of these statements are correct?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_641b1822\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">04</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n1.  Regression line represents a conditional mean of the explanatory variable X given the value of the outcome variable Y.\n2.  Extreme values of correlation coefficient (i.e. close to -1 or 1) imply that there is a large substantive effect of X on Y.\n3.  Correlation between X and Y implies there is a causal relationship between them.\n4.  Causal relationship between X and Y implies there is a correlation between them.\n5.  Causal relationship between X and Y implies there is an association between them.\n\n## Association vs. Correlation\n\n![Correlation is a type of association and measures increasing or decreasing trends quantified using correlation coefficients.](https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnmeth.3587/MediaObjects/41592_2015_Article_BFnmeth3587_Fig1_HTML.jpg)\n\n\n# Causality\n\n## Data Generating Process \n\n-   An unknown process in the real world that \"generates\" the data we are interested in\n-   In social sciences, DGP is often not very precise\n-   Our understanding of DGP comes from the theory and subject knowledge\n\n## Causality\n\n-   A variable $X$ is a cause of a variable $Y$ if $Y$ in any way relies on $X$ for its value.... $X$ is a cause of $Y$ if $Y$ listens to $X$ and decides its value in response to what it hears (Pearl, Glymour, and Jewell 2016, 5--6)\n\n-   This incorporates:\n\n    -   association between $X$ and $Y$\n    -   time ordering: cause precedes outcome\n    -   nonspuriousness: there is plausible relationship\n\n-   **Causal effect** is the change in variable Y that would result from a change in variable X\n\n## Example: Boston Commuters Experiment\n\n-   *Question*: How does intergroup contact impact the immigration attitudes?\n-   **Unit of analysis** (indexed by $i$): individuals\n-   **Treatment variable** $T$: exposure to Spanish-speakers on a train platform (yes or no)\n-   **Treatment group** *(treated units)*: individuals exposed to Spanish-speakers\n-   **Control group** *(untreated units)*: individuals not exposed to Spanish-speakers\n-   **Outcome variable** $Y$: immigration attitudes\n    -   Let's simplify for now and say $Y$ is binary: pro- or anti-immigration\n\n## Causal Effects & Counterfactuals\n\n-   Two **potential outcomes**:\n    -   $Y_{i}(1)$: would commuter $i$ report pro-immigration attitudes if exposed to Spanish-speakers ($T = 1$)?\n    -   $Y_{i}(0)$: would commuter $i$ report pro-immigration attitudes if **not** exposed to Spanish-speakers ($T = 0$)?\n-   **Causal effect**: $Y_{i}(1) -Y_{i}(0)$ (aka **treatment effect**)\n    -   $Y_{i}(1) -Y_{i}(0) = 0$: exposure to Spanish-speakers has no impact on attitudes\n    -   $Y_{i}(1) -Y_{i}(0) = +1$: exposure to Spanish-speakers leads to pro-immigration attitudes\n    -   $Y_{i}(1) - Y_{i}(0) = -1$: exposure to Spanish-speakers leads to anti-immigration attitudes\n\n## Potential Outcomes\n\n|      | Attitude if Treated | Attitude if Control |\n|:-----|:-------------------:|:-------------------:|\n| Jack |   Pro-immigration   |  Anti-immigration   |\n\n<br>\n\n#### More formally:\n\n|      |            |            |\n|:-----|:----------:|:----------:|\n|      | $Y_{i}(1)$ | $Y_{i}(0)$ |\n| Jack |     1      |     0      |\n\n## Fundamental Problem of Causal Inference\n\n|      |            |            |                       |\n|:-----|:----------:|:----------:|:---------------------:|\n|      |            |            |     Causal Effect     |\n|      | $Y_{i}(1)$ | $Y_{i}(0)$ | $Y_{i}(1) - Y_{i}(0)$ |\n| Jack |     1      |     0      |           1           |\n\n-   We cannot observe $Y_{i}(1) - Y_{i}(0)$ in real life though:\n    -   We only observe one of the two potential outcomes $Y_{i}(1)$ or $Y_{i}(0)$\n    -   To infer causal effect, we need to infer the missing *counterfactuals*\n\n## Multiple Units\n\n|      |            |            |                       |\n|:-----|:----------:|:----------:|:---------------------:|\n|      | $Y_{i}(1)$ | $Y_{i}(0)$ | $Y_{i}(1) - Y_{i}(0)$ |\n| Jack |     1      |     0      |           1           |\n| Dan  |     0      |     0      |           0           |\n| Anne |     1      |     0      |           1           |\n| Yao  |     0      |     0      |           0           |\n| Judy |     0      |     1      |          -1           |\n\n\n-   Individual treatment effects: value of $Y_{i}(1) - Y_{i}(0)$ for each $i$\n-   **Average treatment effect**: mean of all the individual causal effects\n$ATE = \\frac{1 + 0+ 1+0+(-1)}{5} = 0.2$\n\n## Back to Real World...\n\n|      |            |            |                       |\n|:-----|:----------:|:----------:|:---------------------:|\n|      | $Y_{i}(1)$ | $Y_{i}(0)$ | $Y_{i}(1) - Y_{i}(0)$ |\n| Jack |     ?      |     0      |           ?           |\n| Dan  |     0      |     ?      |           ?           |\n| Anne |     1      |     ?      |           ?           |\n| Yao  |     0      |     ?      |           ?           |\n| Judy |     ?      |     1      |           ?           |\n\n## Randomized Experiment as a Solution\n\n-   Each unit's treatment assignment is determined by chance\n-   Randomization ensures balance between treatment and control group:\n    -   they are identical *on average*\n    -   we shouldn't see large differences between treatment and control group on *pretreatment* variable\n\n## ATE vs. Difference-in-Means\n\n<br>\n\nWe want to estimate the average causal effects over all units:\n\n$$\\text{Average Treatment Effect} = \\frac{\\sum^n_{i=1} (Y_{i}(1) - Y_{i}(0))}{n}$$ But we can only estimate instead:\n\n$$\n\\text{Difference in means} = \\overline Y_{i}(1) - \\overline Y_{i}(0)\n$$\n\nThis is a pretty good estimate of ATE if randomization worked!\n\n\n# Casual Diagrams\n\n## Directed Acyclic Graphs (DAGs)\n\n**Nodes**: variables in the DGP \n\\\n**Arrows**: causal relationships in the DGP (associations)\n\\\n**Direction**: from the cause variable to the caused variable\n\n::: columns\n::: {.column width=\"60%\"}\n*Directed:* Each **node** has an arrow that points to another node\n\n*Acyclic:* You can't cycle back to a node (and arrows only have one direction)\n\n*Graph:* Well...it is a graph.\n:::\n\n::: {.column width=\"40%\"}\n\n```{dot}\n//| echo: false\n//| fig-width: 4\n//| fig-height: 4\n//| out-width: 100%\ndigraph D {\n  node [shape=circle];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"X\"];\n  b [label = \"Y\"];\n  c [label = \"Z\"];\n  \n  {rank=same a b};\n  {rank=sink c};\n  a->b;\n  c->a;\n  c->b;\n}\n```\n\n\n<!-- ```{r} -->\n\n<!-- dagify( -->\n\n<!--   Y ~ X + Z, -->\n\n<!--   X ~ Z, -->\n\n<!--   coords = list(x = c(X = 1, Y = 3, Z = 2), -->\n\n<!--                 y = c(X = 1, Y = 1, Z = 2)) -->\n\n<!-- ) %>%  -->\n\n<!--   ggplot(aes(x = x, y = y, xend = xend, yend = yend)) + -->\n\n<!--   geom_dag_edges() + -->\n\n<!--   geom_dag_point(color = \"#ffffff\", size = 14) + -->\n\n<!--   geom_dag_text(color = \"black\", size = 5) + -->\n\n<!--   theme_dag() -->\n\n<!-- ``` -->\n:::\n:::\n\n<!-- ## Acyclicalness -->\n\n<!-- What if there's something that really is cyclical? -->\n\n<!-- > Wealth â†’ Power â†’ Wealth -->\n\n<!-- This isn't acyclic! Wealth â†” Power -->\n\n<!-- Split the node into different time periods -->\n\n\n## Major Types of Association\n\n::: columns\n::: {.column width=\"33%\"}\n#### Confounding <br>(Fork)\n\n\n```{dot}\n//| echo: false\n//| fig-width: 3\n//| fig-height: 3\n//| out-width: 100%\ndigraph D {\n  node [shape=circle];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"X\"];\n  b [label = \"Y\"];\n  c [label = \"Z\"];\n  \n  {rank=same a b};\n  {rank=sink c};\n  a->b;\n  c->a;\n  c->b;\n}\n```\n\n\nCommon cause\n\n:::\n\n::: {.column width=\"33%\"}\n#### Causation <br>(Chain)\n\n\n```{dot}\n//| echo: false\n//| fig-width: 3\n//| fig-height: 3\n//| out-width: 100%\ndigraph D {\n  node [shape=circle];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"X\"];\n  b [label = \"Y\"];\n  c [label = \"Z\"];\n  \n  {rank=same a b};\n  {rank=sink c};\n  a->b;\n  a->c;\n  c->b;\n}\n```\n\nMediation\n\n:::\n\n::: {.column width=\"33%\"}\n#### Collision <br>(Inverted Fork)\n\n\n```{dot}\n//| echo: false\n//| fig-width: 3\n//| fig-height: 3\n//| out-width: 100%\ndigraph D {\n  node [shape=circle];\n  edge [len = 1.2, arrowhead = vee];\n  a [label = \"X\"];\n  b [label = \"Y\"];\n  c [label = \"Z\"];\n  \n  {rank=same a b};\n  {rank=sink c};\n  a->b;\n  a->c;\n  b->c;\n}\n```\n\nSelection /\nendogeneity\n\n:::\n:::\n\n## Confounding\n\n#### Effect of money on elections\n\n::: columns\n::: {.column width=\"50%\"}\n![](https://evalf22.classes.andrewheiss.com/slides/04-slides_files/figure-html/money-elections-1.png)\n::: \n::: {.column width=\"50%\"}\n\n1. Find the part of campaign money that is explained by quality, remove it.\n\n2. Find the part of win margin that is explained by quality, remove it. \n\n3. Find the relationship between the residual part of money and residual part of win margin.\nThis is the *causal effect*.\n\n::: \n::: \n\n## Campaign Example\n\n![](https://www.andrewheiss.com/research/chapters/heiss-causal-inference-2021/money-votes-complex.png)\n\n## Collider\n\nHeight is unrelated to basketball skillâ€¦ among NBA players\n\n![](https://evalf22.classes.andrewheiss.com/slides/04-slides_files/figure-html/nba-dag-1.png)\n- Colliders can create fake causal effects\n\n- Colliders can hide real causal effects\n\n\n<!-- Compare candidates as if they had the same quality -->\n\n<!-- Remove differences that are predicted by quality -->\n\n<!-- Hold quality constant -->\n<!-- ## Mediation  -->\n\n<!-- ## Collider -->\n\n<!-- - Example of a collider in NBA  -->\n\n<!-- - Make a plot  -->\n\n<!-- - Discuss the relationship you observe  -->\n\n<!-- - Can you think of a reason why you have such a relationship?  -->\n\n<!-- --- -->\n\n## Causal Identification\n\n- DAGs help us with the process of identification \n\n-   Causal effect is *identified* if the association between treatment and outcome is properly stripped and isolated\n-   Identification implies that:\n    -   All alternative stories are ruled out\n    -   We have enough information to answer a specific causal inference question\n-   Sometimes we cannot identify the effect with our data alone\n\n\n```{dot}\n//| fig-width: 4\n//| echo: false\ndigraph D {\n  node [shape=oval];\n  edge [minlen = 1, arrowhead = vee];\n  a [label = \"Education\"];\n  b [label = \"Health\"];\n  c [label = \"Money\"];\n  \n  {rank=same a b};\n  \n  a->b;\n  c->a;\n  b->a;\n  c->b;\n}\n```\n\n\n<!-- ![](https://pbs.twimg.com/media/FeOfP6XUYAEQ2Oq.jpg) -->\n\n------------------------------------------------------------------------\n\n<!-- ```{dot} -->\n<!-- //| label: fig-dot-firstdag-quarto -->\n<!-- //| fig-cap: \"We expect a causal relationship between x and y, where x influences y\" -->\n<!-- //| fig-width: 4 -->\n<!-- //| echo: false -->\n<!-- digraph D { -->\n<!--   node [shape=oval]; -->\n<!--   edge [minlen = 1, arrowhead = vee]; -->\n<!--   a [label = \"Going to\\nCollege\"]; -->\n<!--   b [label = \"Income\"]; -->\n<!--   c [label = \"Children\"]; -->\n\n<!--   {rank=same a b}; -->\n\n<!--   a->{b, c}; -->\n<!--   c->b; -->\n<!-- } -->\n<!-- ``` -->\n\n<!-- ## Causation and Temporal Ordering -->\n\n<!-- ```{dot} -->\n<!-- //| echo: false -->\n<!-- //| fig-width: 6 -->\n<!-- digraph D { -->\n<!--   node [shape=oval]; -->\n<!--   edge [minlen = 2, arrowhead = vee]; -->\n<!--   a [label = \"Number of Cards\\nSent to You\\nPast Week\"]; -->\n<!--   b [label = \"Your Birthday\"]; -->\n\n<!--   {rank=same a b}; -->\n\n<!--   a->b; -->\n<!-- } -->\n<!-- ``` -->\n\n\n\n\n\n\n## Studying Example \n\n\n```{dot}\n//| echo: false\n//| fig-width: 8\n//| out-width: 100%\ndigraph D {\n  node [shape=plaintext];\n  edge [minlen = 2, arrowhead = vee];\n  a [label = \"Hours Spent\\nStudying\"];\n  b [label = \"Exam\\nPerformance\"];\n  c [label = \"X\"];\n  d [label = \"Y\"];\n  e [label = \"Z\"];\n  \n  {rank=max d};\n  {rank=same c e};\n  {rank=same a b};\n\n  a->b;\n  c->a;\n  c->b;\n  d->b;\n  a->d;\n  a->e;\n  b->e;\n}\n```\n\n\n<!-- ## To-Do List -->\n\n<!-- -   Problem Set 3 (Visualization and Data Wrangling) -->\n\n<!-- -   Readings/videos for week 4 (Intro to Causality) -->\n",
    "supporting": [
      "04-causality_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/countdown-0.3.5/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/countdown-0.3.5/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}