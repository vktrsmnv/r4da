---
title: "Causality"
subtitle: "Data Analytics and Visualization with R<br>Session 4"
title-slide-attributes:
  data-background-size: stretch
  data-slide-number: none
auto-stretch: false
institute: "University of Mannheim<br>Spring 2023"
author: "Viktoriia Semenova"
footer: "[ðŸ”— r4da.live](https://r4da.live/)"
logo: images/logo.png
format:
  revealjs:
    theme: ../slides.scss
    transition: fade
    incremental: true   
    slide-number: true
    chalkboard: true
execute:
  echo: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
p_needed <- c("tidyverse", "janitor", "icons", "countdown", "showtext", "ggdag", "gt")

# check if they are already installed, install if not installed
lapply(p_needed[!(p_needed %in% rownames(installed.packages()))], install.packages, repos = "http://cran.us.r-project.org")

# load the packages
lapply(p_needed, library, character.only = TRUE)

# set width of code output
options(width = 65)

# set figure parameters for knitr
knitr::opts_chunk$set(
  fig.width = 7, # 7" width
  fig.asp = 0.618, # the golden ratio
  fig.retina = 3, # dpi multiplier for displaying HTML output on retina
  fig.align = "center", # center align figures
  dpi = 300 # higher dpi, sharper image
)


font_add_google(name = "Gochi Hand")
showtext::showtext_auto()
# set theme for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 14)) +
  theme(plot.title = element_text(face = "bold"))

governors <- readr::read_csv("https://r4da.live/files/data/external_data/governors.csv")
trains <- readr::read_tsv("../data/trains.tsv") %>% clean_names()
```

# Warm Up

## Your GitHub Stats ðŸ¤“

::: columns
::: {.column width="50%"}
![](images/PS03_by_hour.png)
:::

::: {.column width="50%"}
![](images/PS01_by_wday.png)
:::
:::

## Quiz: Which of these statements are correct?

```{r}
#| echo: false
countdown(minutes = 4, color_background = "white")
```

1.  Regression line represents a conditional mean of the explanatory variable X given the value of the outcome variable Y.
2.  Extreme values of correlation coefficient (i.e. close to -1 or 1) imply that there is a large substantive effect of X on Y.
3.  Correlation between X and Y implies there is a causal relationship between them.
4.  Causal relationship between X and Y implies there is a correlation between them.
5.  Causal relationship between X and Y implies there is an association between them.

## Association vs. Correlation

![Correlation is a type of association and measures increasing or decreasing trends quantified using correlation coefficients.](https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnmeth.3587/MediaObjects/41592_2015_Article_BFnmeth3587_Fig1_HTML.jpg)


# Causality

## Data Generating Process 

-   An unknown process in the real world that "generates" the data we are interested in
-   In social sciences, DGP is often not very precise
-   Our understanding of DGP comes from the theory and subject knowledge

## Causality

-   A variable $X$ is a cause of a variable $Y$ if $Y$ in any way relies on $X$ for its value.... $X$ is a cause of $Y$ if $Y$ listens to $X$ and decides its value in response to what it hears (Pearl, Glymour, and Jewell 2016, 5--6)

-   This incorporates:

    -   association between $X$ and $Y$
    -   time ordering: cause precedes outcome
    -   nonspuriousness: there is plausible relationship

-   **Causal effect** is the change in variable Y that would result from a change in variable X

## Example: Boston Commuters Experiment

-   *Question*: How does intergroup contact impact the immigration attitudes?
-   **Unit of analysis** (indexed by $i$): individuals
-   **Treatment variable** $T$: exposure to Spanish-speakers on a train platform (yes or no)
-   **Treatment group** *(treated units)*: individuals exposed to Spanish-speakers
-   **Control group** *(untreated units)*: individuals not exposed to Spanish-speakers
-   **Outcome variable** $Y$: immigration attitudes
    -   Let's simplify for now and say $Y$ is binary: pro- or anti-immigration

## Causal Effects & Counterfactuals

-   Two **potential outcomes**:
    -   $Y_{i}(1)$: would commuter $i$ report pro-immigration attitudes if exposed to Spanish-speakers ($T = 1$)?
    -   $Y_{i}(0)$: would commuter $i$ report pro-immigration attitudes if **not** exposed to Spanish-speakers ($T = 0$)?
-   **Causal effect**: $Y_{i}(1) -Y_{i}(0)$ (aka **treatment effect**)
    -   $Y_{i}(1) -Y_{i}(0) = 0$: exposure to Spanish-speakers has no impact on attitudes
    -   $Y_{i}(1) -Y_{i}(0) = +1$: exposure to Spanish-speakers leads to pro-immigration attitudes
    -   $Y_{i}(1) - Y_{i}(0) = -1$: exposure to Spanish-speakers leads to anti-immigration attitudes

## Potential Outcomes

|      | Attitude if Treated | Attitude if Control |
|:-----|:-------------------:|:-------------------:|
| Jack |   Pro-immigration   |  Anti-immigration   |

<br>

#### More formally:

|      |            |            |
|:-----|:----------:|:----------:|
|      | $Y_{i}(1)$ | $Y_{i}(0)$ |
| Jack |     1      |     0      |

## Fundamental Problem of Causal Inference

|      |            |            |                       |
|:-----|:----------:|:----------:|:---------------------:|
|      |            |            |     Causal Effect     |
|      | $Y_{i}(1)$ | $Y_{i}(0)$ | $Y_{i}(1) - Y_{i}(0)$ |
| Jack |     1      |     0      |           1           |

-   We cannot observe $Y_{i}(1) - Y_{i}(0)$ in real life though:
    -   We only observe one of the two potential outcomes $Y_{i}(1)$ or $Y_{i}(0)$
    -   To infer causal effect, we need to infer the missing *counterfactuals*

## Multiple Units

|      |            |            |                       |
|:-----|:----------:|:----------:|:---------------------:|
|      | $Y_{i}(1)$ | $Y_{i}(0)$ | $Y_{i}(1) - Y_{i}(0)$ |
| Jack |     1      |     0      |           1           |
| Dan  |     0      |     0      |           0           |
| Anne |     1      |     0      |           1           |
| Yao  |     0      |     0      |           0           |
| Judy |     0      |     1      |          -1           |


-   Individual treatment effects: value of $Y_{i}(1) - Y_{i}(0)$ for each $i$
-   **Average treatment effect**: mean of all the individual causal effects
$ATE = \frac{1 + 0+ 1+0+(-1)}{5} = 0.2$

## Back to Real World...

|      |            |            |                       |
|:-----|:----------:|:----------:|:---------------------:|
|      | $Y_{i}(1)$ | $Y_{i}(0)$ | $Y_{i}(1) - Y_{i}(0)$ |
| Jack |     ?      |     0      |           ?           |
| Dan  |     0      |     ?      |           ?           |
| Anne |     1      |     ?      |           ?           |
| Yao  |     0      |     ?      |           ?           |
| Judy |     ?      |     1      |           ?           |

## Randomized Experiment as a Solution

-   Each unit's treatment assignment is determined by chance
-   Randomization ensures balance between treatment and control group:
    -   they are identical *on average*
    -   we shouldn't see large differences between treatment and control group on *pretreatment* variable

## ATE vs. Difference-in-Means

<br>

We want to estimate the average causal effects over all units:

$$\text{Average Treatment Effect} = \frac{\sum^n_{i=1} (Y_{i}(1) - Y_{i}(0))}{n}$$ But we can only estimate instead:

$$
\text{Difference in means} = \overline Y_{i}(1) - \overline Y_{i}(0)
$$

This is a pretty good estimate of ATE if randomization worked!


# Casual Diagrams

## Directed Acyclic Graphs (DAGs)

**Nodes**: variables in the DGP 
\
**Arrows**: causal relationships in the DGP (associations)
\
**Direction**: from the cause variable to the caused variable

::: columns
::: {.column width="60%"}
*Directed:* Each **node** has an arrow that points to another node

*Acyclic:* You can't cycle back to a node (and arrows only have one direction)

*Graph:* Well...it is a graph.
:::

::: {.column width="40%"}
```{dot}
//| echo: false
//| fig-width: 6
//| fig-height: 4
//| out-width: 100%
digraph D {
  node [shape=circle];
  edge [len = 1.2, arrowhead = vee];
  a [label = "X"];
  b [label = "Y"];
  c [label = "Z"];
  
  {rank=same a b};
  {rank=sink c};
  a->b;
  c->a;
  c->b;
}
```

<!-- ```{r} -->

<!-- dagify( -->

<!--   Y ~ X + Z, -->

<!--   X ~ Z, -->

<!--   coords = list(x = c(X = 1, Y = 3, Z = 2), -->

<!--                 y = c(X = 1, Y = 1, Z = 2)) -->

<!-- ) %>%  -->

<!--   ggplot(aes(x = x, y = y, xend = xend, yend = yend)) + -->

<!--   geom_dag_edges() + -->

<!--   geom_dag_point(color = "#ffffff", size = 14) + -->

<!--   geom_dag_text(color = "black", size = 5) + -->

<!--   theme_dag() -->

<!-- ``` -->
:::
:::

<!-- ## Acyclicalness -->

<!-- What if there's something that really is cyclical? -->

<!-- > Wealth â†’ Power â†’ Wealth -->

<!-- This isn't acyclic! Wealth â†” Power -->

<!-- Split the node into different time periods -->


## Major Types of Association

::: columns
::: {.column width="33%"}
#### Confounding <br>(Fork)

```{dot}
//| echo: false
//| fig-width: 3
//| fig-height: 3
//| out-width: 100%
digraph D {
  node [shape=circle];
  edge [len = 1.2, arrowhead = vee];
  a [label = "X"];
  b [label = "Y"];
  c [label = "Z"];
  
  {rank=same a b};
  {rank=sink c};
  a->b;
  c->a;
  c->b;
}
```

Common cause

:::

::: {.column width="33%"}
#### Causation <br>(Chain)

```{dot}
//| echo: false
//| fig-width: 3
//| fig-height: 3
//| out-width: 100%
digraph D {
  node [shape=circle];
  edge [len = 1.2, arrowhead = vee];
  a [label = "X"];
  b [label = "Y"];
  c [label = "Z"];
  
  {rank=same a b};
  {rank=sink c};
  a->b;
  a->c;
  c->b;
}
```
Mediation

:::

::: {.column width="33%"}
#### Collision <br>(Inverted Fork)

```{dot}
//| echo: false
//| fig-width: 3
//| fig-height: 3
//| out-width: 100%
digraph D {
  node [shape=circle];
  edge [len = 1.2, arrowhead = vee];
  a [label = "X"];
  b [label = "Y"];
  c [label = "Z"];
  
  {rank=same a b};
  {rank=sink c};
  a->b;
  a->c;
  b->c;
}
```
Selection /
endogeneity

:::
:::

## Confounding

#### Effect of money on elections

::: columns
::: {.column width="50%"}
![](https://evalf22.classes.andrewheiss.com/slides/04-slides_files/figure-html/money-elections-1.png)
::: 
::: {.column width="50%"}

1. Find the part of campaign money that is explained by quality, remove it.

2. Find the part of win margin that is explained by quality, remove it. 

3. Find the relationship between the residual part of money and residual part of win margin.
This is the *causal effect*.

::: 
::: 

## Campaign Example

![](https://www.andrewheiss.com/research/chapters/heiss-causal-inference-2021/money-votes-complex.png)

## Collider

Height is unrelated to basketball skillâ€¦ among NBA players

![](https://evalf22.classes.andrewheiss.com/slides/04-slides_files/figure-html/nba-dag-1.png)
- Colliders can create fake causal effects

- Colliders can hide real causal effects


<!-- Compare candidates as if they had the same quality -->

<!-- Remove differences that are predicted by quality -->

<!-- Hold quality constant -->
<!-- ## Mediation  -->

<!-- ## Collider -->

<!-- - Example of a collider in NBA  -->

<!-- - Make a plot  -->

<!-- - Discuss the relationship you observe  -->

<!-- - Can you think of a reason why you have such a relationship?  -->

<!-- --- -->

## Causal Identification

- DAGs help us with the process of identification 

-   Causal effect is *identified* if the association between treatment and outcome is properly stripped and isolated
-   Identification implies that:
    -   All alternative stories are ruled out
    -   We have enough information to answer a specific causal inference question
-   Sometimes we cannot identify the effect with our data alone

```{dot}
//| fig-width: 4
//| echo: false
digraph D {
  node [shape=oval];
  edge [minlen = 1, arrowhead = vee];
  a [label = "Education"];
  b [label = "Health"];
  c [label = "Money"];
  
  {rank=same a b};
  
  a->b;
  c->a;
  b->a;
  c->b;
}
```

<!-- ![](https://pbs.twimg.com/media/FeOfP6XUYAEQ2Oq.jpg) -->

------------------------------------------------------------------------

<!-- ```{dot} -->
<!-- //| label: fig-dot-firstdag-quarto -->
<!-- //| fig-cap: "We expect a causal relationship between x and y, where x influences y" -->
<!-- //| fig-width: 4 -->
<!-- //| echo: false -->
<!-- digraph D { -->
<!--   node [shape=oval]; -->
<!--   edge [minlen = 1, arrowhead = vee]; -->
<!--   a [label = "Going to\nCollege"]; -->
<!--   b [label = "Income"]; -->
<!--   c [label = "Children"]; -->

<!--   {rank=same a b}; -->

<!--   a->{b, c}; -->
<!--   c->b; -->
<!-- } -->
<!-- ``` -->

<!-- ## Causation and Temporal Ordering -->

<!-- ```{dot} -->
<!-- //| echo: false -->
<!-- //| fig-width: 6 -->
<!-- digraph D { -->
<!--   node [shape=oval]; -->
<!--   edge [minlen = 2, arrowhead = vee]; -->
<!--   a [label = "Number of Cards\nSent to You\nPast Week"]; -->
<!--   b [label = "Your Birthday"]; -->

<!--   {rank=same a b}; -->

<!--   a->b; -->
<!-- } -->
<!-- ``` -->






## Studying Example 

```{dot}
//| echo: false
//| fig-width: 8
//| out-width: 100%
digraph D {
  node [shape=plaintext];
  edge [minlen = 2, arrowhead = vee];
  a [label = "Hours Spent\nStudying"];
  b [label = "Exam\nPerformance"];
  c [label = "X"];
  d [label = "Y"];
  e [label = "Z"];
  
  {rank=max d};
  {rank=same c e};
  {rank=same a b};

  a->b;
  c->a;
  c->b;
  d->b;
  a->d;
  a->e;
  b->e;
}
```

<!-- ## To-Do List -->

<!-- -   Problem Set 3 (Visualization and Data Wrangling) -->

<!-- -   Readings/videos for week 4 (Intro to Causality) -->
